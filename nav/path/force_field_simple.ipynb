{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a bunch of helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def circle(x, y, r, n=100):\n",
    "    t = linspace(0, 2*pi, n)\n",
    "    return r*cos(t)+x, r*sin(t)+y\n",
    "\n",
    "def phi(x):\n",
    "    q = np.exp(x)\n",
    "    return 1/(1+q)\n",
    "\n",
    "def d_phi(x):\n",
    "    q = 1/(1+np.exp(x))\n",
    "    return -q*(1-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_phi = np.vectorize(phi)\n",
    "vec_d_phi = np.vectorize(d_phi)\n",
    "\n",
    "def compute_loss(curr_pos, circ_mat, circ_rad, C):\n",
    "    all_dist = C*(linalg.norm(circ_mat - curr_pos[:,newaxis], axis=0)**2/circ_rad - 1)\n",
    "    return np.sum(phi(all_dist))\n",
    "    \n",
    "def loss(pos_mat, circ_mat, circ_rad, C):\n",
    "    return np.sum(np.apply_along_axis(lambda x: compute_loss(x, circ_mat, circ_rad, C), 0, pos_mat))\n",
    "\n",
    "def compute_dloss(curr_pos, circ_mat, circ_rad, C):\n",
    "    dif_mat = curr_pos[:,newaxis] - circ_mat\n",
    "    all_dist = C*(linalg.norm(dif_mat, axis=0)**2/circ_rad - 1)\n",
    "    return 2*C*np.sum(d_phi(all_dist)*dif_mat/circ_rad, axis=1)\n",
    "\n",
    "def dloss(pos_mat, circ_mat, circ_rad, C):\n",
    "    return np.apply_along_axis(lambda x: compute_dloss(x, circ_mat, circ_rad, C), 0, pos_mat)\n",
    "\n",
    "def complete_dloss(pos_mat, circ_mat, circ_rad, C, K):\n",
    "    dloss_obstacles = dloss(pos_mat, circ_mat, circ_rad, C)[:,1:-1]\n",
    "    diff_mat = -pos_mat[:,:-2] + 2*pos_mat[:,1:-1] - pos_mat[:,2:]\n",
    "    zeros_mat = np.zeros(2)[:,newaxis]\n",
    "    return np.c_[zeros_mat, dloss_obstacles + K*diff_mat, zeros_mat]\n",
    "\n",
    "def complete_loss(pos_mat, circ_mat, circ_rad, C, K):\n",
    "    loss_obstacles = loss(pos_mat, circ_mat, circ_rad, C)\n",
    "    loss_diff = sum(linalg.norm(pos_mat[:,1:] - pos_mat[:,:-1], axis=0))\n",
    "    return loss_obstacles + K*loss_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the initial path guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_path(points, circles, radii, plot_title=''):\n",
    "    plot(points[0,:], points[1,:], '-')\n",
    "    for idx in range(len(radii)):\n",
    "        curr_circle = circle(circles[0, idx], circles[1, idx], radii[idx])\n",
    "        plot(curr_circle[0], curr_circle[1], 'r')\n",
    "        \n",
    "    gca().set_aspect('equal')\n",
    "    title(plot_title)\n",
    "    #xlim(-1, 1)\n",
    "    #ylim(-.7, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. ]\n",
      " [ 0.1]]\n",
      "[ 0.25]\n"
     ]
    }
   ],
   "source": [
    "N_points = 100\n",
    "points = np.zeros((2, N_points)) # the initial set of points\n",
    "points[0,:] = np.linspace(-1, 1, N_points)\n",
    "\n",
    "circ_pos = np.array([0, 0.1])[:,newaxis]\n",
    "print(circ_pos)\n",
    "circ_radius2 = np.array([(1/2.)**2])\n",
    "print(circ_radius2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAADWCAYAAADYZ1XhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngVIBEBFpoFQAREQaKBUAEZEG6v8BAYuTEYJr5EsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120f68e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_path(points, circ_pos, sqrt(circ_radius2), 'Initial guess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to use the classical momentum technique; e.g. consider some 'velocity' vector $v_t$, where $\\eta > 0$ is the learning rate, and where $0 < \\mu < 1$ is the momentum coefficient, then we have the following scheme, for $\\theta_t$ being the argument at iteration $t$, which we're minimizing over:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_t &=& \\mu v_{t-1} - \\eta \\nabla f(\\theta_{t-1})\\\\\n",
    "\\theta_t &=& \\theta_{t-1} + v_t\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Running this new iterative scheme is much faster than just vanilla gradient descent, though it doesn't fully optimize the function (e.g. compare the `spring_backtracking_momentum` to `spring_step_backtracking`), so it might be worth doing a second-pass using just a simple gradient descent with line search to complete the optimization. There's also this question of whether this would even be necessary or if we just want to do 'good enough' for our purposes.\n",
    "\n",
    "Note also that we send $C\\to\\infty$ at the same time that we optimize the objective: this is done to save time. E.g. while we could optimize first over each $C$ and then rework the problem after each $C$ has converged (which may be a possibility to evaluate); in general, the intial steps will be quite crappy, and we don't really care about convergence for small $C$ (soft-wall constraints), but rather we only really want the solution to the problem for larger $C$; this seems like a reasonable tradeoff, even though we may not be guaranteed to reach a local optimum point here, anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-50. -15.  25.  50. -25.]\n",
      " [ 10. -50.  25.  -5.  50.]]\n",
      "[  400.  1600.   625.   400.   625.]\n",
      "On iteration 0\n",
      "Current step size : 0.002\n",
      "On iteration 10\n",
      "Current step size : 1.31072\n",
      "On iteration 20\n",
      "Current step size : 0.09134385233318165\n",
      "Converged in cooling step; increasing schedule(C=1.002603252601495) and resetting velocity\n",
      "On iteration 30\n",
      "Current step size : 3.2e-06\n",
      "On iteration 40\n",
      "Current step size : 0.0032768\n",
      "Converged in cooling step; increasing schedule(C=1.1047399465886845) and resetting velocity\n",
      "On iteration 50\n",
      "Current step size : 2.56e-05\n",
      "On iteration 60\n",
      "Current step size : 0.0262144\n",
      "Converged in cooling step; increasing schedule(C=1.217403186611115) and resetting velocity\n",
      "On iteration 70\n",
      "Current step size : 0.0001024\n",
      "Converged in cooling step; increasing schedule(C=1.3415560135644309) and resetting velocity\n",
      "On iteration 80\n",
      "Current step size : 4e-07\n",
      "On iteration 90\n",
      "Current step size : 0.0004096\n",
      "Converged in cooling step; increasing schedule(C=1.4783701548711343) and resetting velocity\n",
      "On iteration 100\n",
      "Current step size : 1.6e-06\n",
      "On iteration 110\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=1.6291368326893458) and resetting velocity\n",
      "On iteration 120\n",
      "Current step size : 6.4e-06\n",
      "On iteration 130\n",
      "Current step size : 0.0065536\n",
      "Converged in cooling step; increasing schedule(C=1.795278950187156) and resetting velocity\n",
      "On iteration 140\n",
      "Current step size : 2.56e-05\n",
      "On iteration 150\n",
      "Current step size : 0.02097152\n",
      "Converged in cooling step; increasing schedule(C=1.9783645205937623) and resetting velocity\n",
      "On iteration 160\n",
      "Current step size : 0.0001024\n",
      "Converged in cooling step; increasing schedule(C=2.180121465767848) and resetting velocity\n",
      "On iteration 170\n",
      "Current step size : 4e-07\n",
      "On iteration 180\n",
      "Current step size : 0.0004096\n",
      "Converged in cooling step; increasing schedule(C=2.4024539239488902) and resetting velocity\n",
      "On iteration 190\n",
      "Current step size : 1.6e-06\n",
      "On iteration 200\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=2.6474602206004025) and resetting velocity\n",
      "On iteration 210\n",
      "Current step size : 6.4e-06\n",
      "On iteration 220\n",
      "Current step size : 0.0065536\n",
      "Converged in cooling step; increasing schedule(C=2.9174526719500347) and resetting velocity\n",
      "On iteration 230\n",
      "Current step size : 2.56e-05\n",
      "On iteration 240\n",
      "Current step size : 0.0262144\n",
      "Converged in cooling step; increasing schedule(C=3.215300906068846) and resetting velocity\n",
      "On iteration 250\n",
      "Current step size : 5.12e-05\n",
      "On iteration 260\n",
      "Current step size : 0.0524288\n",
      "Converged in cooling step; increasing schedule(C=3.5439113826816757) and resetting velocity\n",
      "On iteration 270\n",
      "Current step size : 5.12e-05\n",
      "On iteration 280\n",
      "Current step size : 0.0524288\n",
      "Converged in cooling step; increasing schedule(C=3.9064971478662067) and resetting velocity\n",
      "On iteration 290\n",
      "Current step size : 2.56e-05\n",
      "On iteration 300\n",
      "Current step size : 0.0262144\n",
      "Converged in cooling step; increasing schedule(C=4.306610518780666) and resetting velocity\n",
      "On iteration 310\n",
      "Current step size : 6.4e-06\n",
      "On iteration 320\n",
      "Current step size : 0.0065536\n",
      "On iteration 330\n",
      "Current step size : 0.09671406556917042\n",
      "Converged in cooling step; increasing schedule(C=4.74960388519904) and resetting velocity\n",
      "On iteration 340\n",
      "Current step size : 0.0001024\n",
      "On iteration 350\n",
      "Current step size : 0.1048576\n",
      "On iteration 360\n",
      "Current step size : 0.10633823966279346\n",
      "On iteration 370\n",
      "Current step size : 0.08627182933488235\n",
      "On iteration 380\n",
      "Current step size : 0.0874900289913209\n",
      "On iteration 390\n",
      "Current step size : 0.08872543021186664\n",
      "On iteration 400\n",
      "Current step size : 0.08997827589086461\n",
      "On iteration 410\n",
      "Current step size : 0.09124881235244475\n",
      "On iteration 420\n",
      "Current step size : 0.07402983151916152\n",
      "On iteration 430\n",
      "Current step size : 0.060060134630438404\n",
      "Converged in cooling step; increasing schedule(C=5.278124845898873) and resetting velocity\n",
      "On iteration 440\n",
      "Current step size : 2.56e-05\n",
      "Converged in cooling step; increasing schedule(C=5.81581532397478) and resetting velocity\n",
      "On iteration 450\n",
      "Current step size : 2e-07\n",
      "On iteration 460\n",
      "Current step size : 0.0002048\n",
      "On iteration 470\n",
      "Current step size : 0.16777216\n",
      "Converged in cooling step; increasing schedule(C=6.4114859172996885) and resetting velocity\n",
      "On iteration 480\n",
      "Current step size : 5.12e-05\n",
      "On iteration 490\n",
      "Current step size : 0.0524288\n",
      "Converged in cooling step; increasing schedule(C=7.067459861415314) and resetting velocity\n",
      "On iteration 500\n",
      "Current step size : 2.56e-05\n",
      "On iteration 510\n",
      "Current step size : 0.0262144\n",
      "Converged in cooling step; increasing schedule(C=7.790548016013341) and resetting velocity\n",
      "On iteration 520\n",
      "Current step size : 1.28e-05\n",
      "On iteration 530\n",
      "Current step size : 0.0131072\n",
      "Converged in cooling step; increasing schedule(C=8.587616991100283) and resetting velocity\n",
      "On iteration 540\n",
      "Current step size : 6.4e-06\n",
      "On iteration 550\n",
      "Current step size : 0.0065536\n",
      "Converged in cooling step; increasing schedule(C=9.465289406483695) and resetting velocity\n",
      "On iteration 560\n",
      "Current step size : 6.4e-06\n",
      "On iteration 570\n",
      "Current step size : 0.0065536\n",
      "Converged in cooling step; increasing schedule(C=10.434748414837955) and resetting velocity\n",
      "On iteration 580\n",
      "Current step size : 1.6e-06\n",
      "On iteration 590\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=11.501201524549318) and resetting velocity\n",
      "On iteration 600\n",
      "Current step size : 1.6e-06\n",
      "On iteration 610\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=12.676648372298084) and resetting velocity\n",
      "On iteration 620\n",
      "Current step size : 1.6e-06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ischeinfeld/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: RuntimeWarning: overflow encountered in exp\n",
      "/Users/ischeinfeld/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On iteration 630\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=13.972228346045322) and resetting velocity\n",
      "On iteration 640\n",
      "Current step size : 1.6e-06\n",
      "On iteration 650\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=15.401759324427271) and resetting velocity\n",
      "On iteration 660\n",
      "Current step size : 8e-07\n",
      "On iteration 670\n",
      "Current step size : 0.0008192\n",
      "On iteration 680\n",
      "Current step size : 0.2199023255552001\n",
      "Converged in cooling step; increasing schedule(C=16.98094460107617) and resetting velocity\n",
      "On iteration 690\n",
      "Current step size : 0.0001024\n",
      "On iteration 700\n",
      "Current step size : 0.1048576\n",
      "Converged in cooling step; increasing schedule(C=18.72204814209046) and resetting velocity\n",
      "On iteration 710\n",
      "Current step size : 1.28e-05\n",
      "Converged in cooling step; increasing schedule(C=20.625165969072754) and resetting velocity\n",
      "On iteration 720\n",
      "Current step size : 4e-07\n",
      "On iteration 730\n",
      "Current step size : 0.0004096\n",
      "On iteration 740\n",
      "Current step size : 0.268435456\n",
      "Converged in cooling step; increasing schedule(C=22.739921675918648) and resetting velocity\n",
      "On iteration 750\n",
      "Current step size : 5.12e-05\n",
      "Converged in cooling step; increasing schedule(C=25.043947054810157) and resetting velocity\n",
      "On iteration 760\n",
      "Current step size : 1.28e-05\n",
      "Converged in cooling step; increasing schedule(C=27.584176100166925) and resetting velocity\n",
      "On iteration 770\n",
      "Current step size : 1.6e-06\n",
      "On iteration 780\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=30.388139474282305) and resetting velocity\n",
      "On iteration 790\n",
      "Current step size : 5.12e-05\n",
      "On iteration 800\n",
      "Current step size : 0.0524288\n",
      "Converged in cooling step; increasing schedule(C=33.50392004400138) and resetting velocity\n",
      "On iteration 810\n",
      "Current step size : 6.4e-06\n",
      "On iteration 820\n",
      "Current step size : 0.0065536\n",
      "Converged in cooling step; increasing schedule(C=36.9243982978932) and resetting velocity\n",
      "On iteration 830\n",
      "Current step size : 1.28e-05\n",
      "On iteration 840\n",
      "Current step size : 0.0131072\n",
      "Converged in cooling step; increasing schedule(C=40.71035968794504) and resetting velocity\n",
      "On iteration 850\n",
      "Current step size : 1.6e-06\n",
      "Converged in cooling step; increasing schedule(C=44.82619720939904) and resetting velocity\n",
      "On iteration 860\n",
      "Current step size : 1.6e-06\n",
      "Converged in cooling step; increasing schedule(C=49.35814794215499) and resetting velocity\n",
      "On iteration 870\n",
      "Current step size : 1.6e-06\n",
      "Converged in cooling step; increasing schedule(C=54.34284685322119) and resetting velocity\n",
      "On iteration 880\n",
      "Current step size : 3.2e-06\n",
      "Converged in cooling step; increasing schedule(C=59.83095248171739) and resetting velocity\n",
      "On iteration 890\n",
      "Current step size : 6.4e-06\n",
      "Converged in cooling step; increasing schedule(C=65.87330407143243) and resetting velocity\n",
      "On iteration 900\n",
      "Current step size : 1.28e-05\n",
      "Converged in cooling step; increasing schedule(C=72.5258751415224) and resetting velocity\n",
      "On iteration 910\n",
      "Current step size : 2.56e-05\n",
      "Converged in cooling step; increasing schedule(C=79.85029199901372) and resetting velocity\n",
      "On iteration 920\n",
      "Current step size : 5.12e-05\n",
      "Converged in cooling step; increasing schedule(C=87.914404616089) and resetting velocity\n",
      "Converged in cooling step; increasing schedule(C=96.79291516049659) and resetting velocity\n",
      "On iteration 930\n",
      "Current step size : 2e-07\n",
      "Converged in cooling step; increasing schedule(C=106.5787268084947) and resetting velocity\n",
      "On iteration 940\n",
      "Current step size : 2e-07\n",
      "Converged in cooling step; increasing schedule(C=117.35388885937411) and resetting velocity\n",
      "On iteration 950\n",
      "Current step size : 2e-07\n",
      "On iteration 960\n",
      "Current step size : 0.0002048\n",
      "Converged in cooling step; increasing schedule(C=129.2571945329459) and resetting velocity\n",
      "On iteration 970\n",
      "Current step size : 2.56e-05\n",
      "Converged in cooling step; increasing schedule(C=142.38209950404172) and resetting velocity\n",
      "On iteration 980\n",
      "Current step size : 1.6e-06\n",
      "On iteration 990\n",
      "Current step size : 0.0016384\n",
      "Converged in cooling step; increasing schedule(C=156.85540444123612) and resetting velocity\n",
      "On iteration 1000\n",
      "Current step size : 5.12e-05\n"
     ]
    }
   ],
   "source": [
    "MAX_ITER = 1000\n",
    "INIT_STEP_SIZE = 1e-3\n",
    "MIN_STEP = 1e-2\n",
    "RESET_STEP_SIZE = 1e-7\n",
    "COOLING_SCHEDULE = 1.0001\n",
    "FAST_COOLING_SCHEDULE = 1.1\n",
    "INIT_CONSTRAINT_HARDNESS = 1\n",
    "INIT_SPRING_HARDNESS = 20\n",
    "MAX_TIME_INCREASE = 10\n",
    "MOMENTUM_CHANGE = .2\n",
    "\n",
    "curr_pos = copy(points * 100)\n",
    "constraint_hardness = INIT_CONSTRAINT_HARDNESS\n",
    "\n",
    "circ_pos = array([[-.5, .1], [-.15, -.5], [.25, .25], [.5, -.05], [-.25, .5]]).T * 100\n",
    "circ_radius2 = (array([.2, .4, .25, .2, .25]) * 100) **2\n",
    "\n",
    "print(circ_pos)\n",
    "print(circ_radius2)\n",
    "\n",
    "count = 0\n",
    "curr_step = INIT_STEP_SIZE\n",
    "prev_loss = float('inf')\n",
    "momentum = .99\n",
    "\n",
    "prev_velocity = np.zeros(curr_pos.shape)\n",
    "curr_velocity = copy(prev_velocity)\n",
    "\n",
    "times_increased = 0\n",
    "converged = False\n",
    "\n",
    "for i in range(MAX_ITER+1):\n",
    "    while True:\n",
    "        # Accelerated gradient (e.g. with momentum)\n",
    "        curr_velocity = momentum * prev_velocity - curr_step*complete_dloss(curr_pos, circ_pos, circ_radius2, constraint_hardness, INIT_SPRING_HARDNESS)\n",
    "        proposed_pos = curr_pos + curr_velocity\n",
    "        curr_loss = complete_loss(proposed_pos, circ_pos, circ_radius2, constraint_hardness, INIT_SPRING_HARDNESS)\n",
    "        \n",
    "        # Ensure decrease\n",
    "        if curr_loss < prev_loss:\n",
    "            curr_pos = proposed_pos\n",
    "            prev_velocity = curr_velocity\n",
    "            prev_loss = curr_loss\n",
    "            curr_step *= 2\n",
    "            times_increased = 0\n",
    "            break\n",
    "        # Otherwise, decrease the step size\n",
    "        else:\n",
    "            curr_step *= .8\n",
    "        if curr_step < MIN_STEP:\n",
    "            if times_increased > MAX_TIME_INCREASE:\n",
    "                print('Cooling schedule is finished. Converged to final result.')\n",
    "                converged = True\n",
    "                break\n",
    "            # Once the cooling step converges, increase the constraint hardness such that the optimization\n",
    "            # Can finish\n",
    "            print('Converged in cooling step; increasing schedule'\n",
    "                  '(C={}) and resetting velocity'.format(constraint_hardness))\n",
    "            prev_velocity = np.zeros(prev_velocity.shape)\n",
    "            constraint_hardness *= FAST_COOLING_SCHEDULE\n",
    "            \n",
    "            curr_step = RESET_STEP_SIZE;\n",
    "            times_increased += 1\n",
    "\n",
    "    if converged:\n",
    "        break\n",
    "    constraint_hardness *= COOLING_SCHEDULE\n",
    "    \n",
    "    \n",
    "    if i%10==0:\n",
    "        plot_path(curr_pos, circ_pos, sqrt(circ_radius2), 'Iteration: {}'.format(i))\n",
    "        savefig('images/iter{:02d}.png'.format(count))\n",
    "        close()\n",
    "        count += 1\n",
    "        print('On iteration {}'.format(i))\n",
    "        print('Current step size : {}'.format(curr_step))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
