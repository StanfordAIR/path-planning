# -*- coding: utf-8 -*-
"""run_benchmark.py
Run benchmarks on different solution techniques
Before running the benchmark, execute the following steps:

1) Train your model using the definition in problem.py. For this, import #1 only.
2) Execute your model on the environments generated by 
   environments.generate(TEST_SIZE, TEST_ID). For this, import #1 and #2. Save a file
   for each environment using np.save( ) titled
   (METHOD_ID)_(TEST_ID)_(1 -> TEST_SIZE).npy, containing a numpy array of locations 
             [[x_start, x2, x3, ..., x_end],
              [y_start, y2, y3, ..., y_end]]
   If no solution is found, save an array containing just start and endpoints, i.e.
             [[x_start, x_end],
              [y_start, y_end]]
   Place these files in the same folder as this file.
3) Finally, run the benchmark. Edit METHOD_ID, TEST_ID, and TEST_SIZE appropriately.
   Then execute `python run_benchmark`.
"""
import numpy as np

from benchmarks.point_to_point import problem
from benchmarks.point_to_point import environments
from benchmarks.point_to_point import draw
from benchmarks.point_to_point import benchmark

### EDIT THESE
METHOD_ID = "graph_optimize_v1"
TEST_ID = 123
TEST_SIZE = 4
###

NUM_DISPLAY_ENVS = 2 # shows n * n environments, must satisfy n * n <= TEST_SIZE
envs = environments.generate(TEST_SIZE, TEST_ID)
#draw.grid(NUM_DISPLAY_ENVS, envs) # displays just the environments without solutions
sols = [np.load("{}_{}_{}.npy".format(METHOD_ID, TEST_ID, i))
        for i in range(TEST_SIZE)]
draw.grid(NUM_DISPLAY_ENVS, envs, sols)
benchmarks = benchmark.run(envs, sols)
print(benchmarks)
